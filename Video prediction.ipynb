{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"Video prediction.ipynb","provenance":[{"file_id":"https://github.com/polimi-ispl/icpr2020dfdc/blob/master/notebook/Video%20prediction.ipynb","timestamp":1617890899282}],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"jupyter":{"outputs_hidden":true},"id":"AwbA2dl-wzSq"},"source":["# Video Face Manipulation Detection Through Ensemble of CNNs\n","Image and Sound Processing Lab - Politecnico di Milano\n","- NicolÃ² Bonettini\n","- Edoardo Daniele Cannas\n","- Sara Mandelli\n","- Luca Bondi\n","- Paolo Bestagini\n"]},{"cell_type":"code","metadata":{"id":"TH96I-fxw_JU"},"source":["!git clone https://github.com/polimi-ispl/icpr2020dfdc\n","!pip install efficientnet-pytorch\n","!pip install -U git+https://github.com/albu/albumentations > /dev/null\n","%cd icpr2020dfdc/notebook"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fPvvLUnIwzSs"},"source":["import torch\n","from torch.utils.model_zoo import load_url\n","import matplotlib.pyplot as plt\n","from scipy.special import expit\n","\n","import sys\n","sys.path.append('..')\n","\n","from blazeface import FaceExtractor, BlazeFace, VideoReader\n","from architectures import fornet,weights\n","from isplutils import utils"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-3smEpNwwzSt"},"source":["## Parameters"]},{"cell_type":"code","metadata":{"id":"QMaTYblPwzSt"},"source":["\"\"\"\n","Choose an architecture between\n","- EfficientNetB4\n","- EfficientNetB4ST\n","- EfficientNetAutoAttB4\n","- EfficientNetAutoAttB4ST\n","- Xception\n","\"\"\"\n","net_model = 'EfficientNetAutoAttB4'\n","\n","\"\"\"\n","Choose a training dataset between\n","- DFDC\n","- FFPP\n","\"\"\"\n","train_db = 'DFDC'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n7sIweSJwzSu"},"source":["device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n","face_policy = 'scale'\n","face_size = 224\n","frames_per_video = 32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q0rPauY4wzSv"},"source":["## Initialization"]},{"cell_type":"code","metadata":{"id":"vMlZk3TSwzSv"},"source":["model_url = weights.weight_url['{:s}_{:s}'.format(net_model,train_db)]\n","net = getattr(fornet,net_model)().eval().to(device)\n","net.load_state_dict(load_url(model_url,map_location=device,check_hash=True))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJD4-cmNwzSw"},"source":["transf = utils.get_transformer(face_policy, face_size, net.get_normalizer(), train=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6jDS1Gs6wzSx"},"source":["facedet = BlazeFace().to(device)\n","facedet.load_weights(\"../blazeface/blazeface.pth\")\n","facedet.load_anchors(\"../blazeface/anchors.npy\")\n","videoreader = VideoReader(verbose=False)\n","video_read_fn = lambda x: videoreader.read_frames(x, num_frames=frames_per_video)\n","face_extractor = FaceExtractor(video_read_fn=video_read_fn,facedet=facedet)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l37M5qzmwzSx"},"source":["## Detect faces"]},{"cell_type":"code","metadata":{"id":"m0vezIhiwzSy"},"source":["vid_real_faces = face_extractor.process_video('samples/lynaeydofd.mp4')\n","vid_fake_faces = face_extractor.process_video('samples/mqzvfufzoq.mp4')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EegInRmbwzS0"},"source":["im_real_face = vid_real_faces[0]['faces'][0]\n","im_fake_face = vid_fake_faces[0]['faces'][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXdk2XqvwzS0"},"source":["fig,ax = plt.subplots(1,2,figsize=(8,4))\n","\n","ax[0].imshow(im_real_face)\n","ax[0].set_title('REAL')\n","\n","ax[1].imshow(im_fake_face)\n","ax[1].set_title('FAKE');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iy6zrfZgwzS1"},"source":["## Predict scores for each frame"]},{"cell_type":"code","metadata":{"id":"tE_xhFoOwzS1"},"source":["# For each frame, we consider the face with the highest confidence score found by BlazeFace (= frame['faces'][0])\n","faces_real_t = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_real_faces if len(frame['faces'])] )\n","faces_fake_t = torch.stack( [ transf(image=frame['faces'][0])['image'] for frame in vid_fake_faces if len(frame['faces'])] )\n","\n","with torch.no_grad():\n","    faces_real_pred = net(faces_real_t.to(device)).cpu().numpy().flatten()\n","    faces_fake_pred = net(faces_fake_t.to(device)).cpu().numpy().flatten()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IYX_2NqswzS1"},"source":["fig,ax = plt.subplots(1,2,figsize=(12,4))\n","\n","ax[0].stem([f['frame_idx'] for f in vid_real_faces if len(f['faces'])],expit(faces_real_pred),use_line_collection=True)\n","ax[0].set_title('REAL')\n","ax[0].set_xlabel('Frame')\n","ax[0].set_ylabel('Score')\n","ax[0].set_ylim([0,1])\n","ax[0].grid(True)\n","\n","ax[1].stem([f['frame_idx'] for f in vid_fake_faces if len(f['faces'])],expit(faces_fake_pred),use_line_collection=True)\n","ax[1].set_title('FAKE')\n","ax[1].set_xlabel('Frame')\n","ax[1].set_ylabel('Score')\n","ax[1].set_ylim([0,1])\n","ax[1].set_yticks([0,1],['REAL','FAKE']);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CuM8dZbvwzS2"},"source":["\"\"\"\n","Print average scores.\n","An average score close to 0 predicts REAL. An average score close to 1 predicts FAKE.\n","\"\"\"\n","print('Average score for REAL video: {:.4f}'.format(expit(faces_real_pred.mean())))\n","print('Average score for FAKE face: {:.4f}'.format(expit(faces_fake_pred.mean())))"],"execution_count":null,"outputs":[]}]}
